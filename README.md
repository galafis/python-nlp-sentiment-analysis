# üáßüá∑ An√°lise de Sentimentos com NLP Avan√ßado | üá∫üá∏ Advanced NLP Sentiment Analysis

<div align="center">

![Hero Image](assets/images/nlp-sentiment-analysis-hero.png)


---

<div align="center">

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Transformers](https://img.shields.io/badge/ü§ó%20Transformers-FFD21E?style=for-the-badge&logoColor=black)
![spaCy](https://img.shields.io/badge/spaCy-09A3D5?style=for-the-badge&logo=spacy&logoColor=white)
![NLTK](https://img.shields.io/badge/NLTK-154f3c?style=for-the-badge&logo=nltk&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)

**Plataforma completa de an√°lise de sentimentos com modelos Transformer e t√©cnicas avan√ßadas de NLP**

[üß† Modelos](#-modelos-implementados) ‚Ä¢ [üìä An√°lises](#-tipos-de-an√°lise) ‚Ä¢ [‚ö° API](#-api-rest) ‚Ä¢ [üéØ Aplica√ß√µes](#-aplica√ß√µes-pr√°ticas)

</div>

---

## üáßüá∑ Portugu√™s

### üß† Vis√£o Geral

Plataforma abrangente de **an√°lise de sentimentos e processamento de linguagem natural** desenvolvida em Python:

- ü§ñ **Modelos Transformer**: BERT, RoBERTa, DistilBERT, XLNet
- üìä **An√°lise Multidimensional**: Sentimento, emo√ß√£o, aspectos, polaridade
- üåç **Multil√≠ngue**: Suporte para portugu√™s, ingl√™s, espanhol
- üîÑ **Pipeline Completo**: Pr√©-processamento, an√°lise, visualiza√ß√£o
- üåê **API REST**: Endpoints para integra√ß√£o em tempo real
- üìà **Dashboard**: Interface interativa com Streamlit

### üéØ Objetivos da Plataforma

- **Analisar sentimentos** em textos de m√∫ltiplas fontes
- **Extrair insights** de dados textuais n√£o estruturados
- **Monitorar opini√£o p√∫blica** em redes sociais e reviews
- **Automatizar classifica√ß√£o** de feedback de clientes
- **Facilitar tomada de decis√£o** baseada em an√°lise textual

### üõ†Ô∏è Stack Tecnol√≥gico

#### NLP e Machine Learning
- **transformers**: Modelos Transformer pr√©-treinados
- **torch**: PyTorch para deep learning
- **tensorflow**: TensorFlow como alternativa
- **scikit-learn**: Algoritmos de ML cl√°ssicos

#### Processamento de Texto
- **spacy**: Processamento avan√ßado de linguagem natural
- **nltk**: Natural Language Toolkit
- **textblob**: An√°lise de sentimentos simples
- **polyglot**: Processamento multil√≠ngue

#### An√°lise e Visualiza√ß√£o
- **pandas**: Manipula√ß√£o de dados textuais
- **numpy**: Computa√ß√£o num√©rica
- **matplotlib**: Visualiza√ß√£o de resultados
- **seaborn**: Gr√°ficos estat√≠sticos
- **plotly**: Visualiza√ß√µes interativas
- **wordcloud**: Nuvens de palavras

#### Web e API
- **fastapi**: API REST para an√°lise em tempo real
- **streamlit**: Dashboard interativo
- **uvicorn**: Servidor ASGI
- **requests**: Cliente HTTP

#### Dados e Storage
- **pymongo**: Integra√ß√£o com MongoDB
- **sqlalchemy**: ORM para bancos relacionais
- **redis**: Cache para resultados
- **elasticsearch**: Busca e an√°lise de texto

### üìã Estrutura da Plataforma

```
python-nlp-sentiment-analysis/
‚îú‚îÄ‚îÄ üìÅ src/                        # C√≥digo fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ models/                 # Modelos de an√°lise
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ transformers/       # Modelos Transformer
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ bert_sentiment.py # BERT para sentimentos
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ roberta_emotion.py # RoBERTa para emo√ß√µes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ distilbert_aspects.py # DistilBERT aspectos
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ multilingual_bert.py # BERT multil√≠ngue
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ classical/          # Modelos cl√°ssicos
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ naive_bayes.py  # Naive Bayes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ svm_classifier.py # SVM
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ logistic_regression.py # Regress√£o log√≠stica
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ random_forest.py # Random Forest
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ ensemble/           # Modelos ensemble
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ voting_classifier.py # Voting classifier
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ stacking_model.py # Stacking
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ weighted_ensemble.py # Ensemble ponderado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ custom/             # Modelos customizados
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ lstm_attention.py # LSTM com aten√ß√£o
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ cnn_text.py     # CNN para texto
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ üìÑ hybrid_model.py # Modelo h√≠brido
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ preprocessing/          # Pr√©-processamento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ text_cleaner.py     # Limpeza de texto
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ tokenizer.py        # Tokeniza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ feature_extractor.py # Extra√ß√£o de features
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ language_detector.py # Detec√ß√£o de idioma
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ emoji_processor.py  # Processamento de emojis
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ analysis/               # M√≥dulos de an√°lise
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sentiment_analyzer.py # An√°lise de sentimentos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ emotion_analyzer.py # An√°lise de emo√ß√µes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ aspect_analyzer.py  # An√°lise de aspectos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ topic_analyzer.py   # An√°lise de t√≥picos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ trend_analyzer.py   # An√°lise de tend√™ncias
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ data_sources/           # Fontes de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ twitter_collector.py # Coleta do Twitter
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ reddit_collector.py # Coleta do Reddit
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ news_collector.py   # Coleta de not√≠cias
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ review_collector.py # Coleta de reviews
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ csv_loader.py       # Carregamento de CSV
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ visualization/          # Visualiza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sentiment_plots.py  # Gr√°ficos de sentimento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ wordcloud_generator.py # Gerador de wordclouds
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ trend_plots.py      # Gr√°ficos de tend√™ncia
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ emotion_radar.py    # Radar de emo√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ interactive_plots.py # Plots interativos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ api/                    # API REST
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ main.py             # Aplica√ß√£o FastAPI principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ endpoints.py        # Endpoints da API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ models.py           # Modelos Pydantic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ dependencies.py     # Depend√™ncias
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ middleware.py       # Middleware customizado
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ dashboard/              # Dashboard Streamlit
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ app.py              # Aplica√ß√£o principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ pages/              # P√°ginas do dashboard
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ real_time_analysis.py # An√°lise em tempo real
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ batch_analysis.py # An√°lise em lote
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ model_comparison.py # Compara√ß√£o de modelos
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ data_explorer.py # Explorador de dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ components/         # Componentes reutiliz√°veis
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ sentiment_meter.py # Medidor de sentimento
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÑ emotion_chart.py # Gr√°fico de emo√ß√µes
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ üìÑ trend_chart.py  # Gr√°fico de tend√™ncias
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ utils/                  # Utilit√°rios
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ config.py           # Configura√ß√µes
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ logger.py           # Sistema de logs
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ cache.py            # Sistema de cache
‚îÇ       ‚îú‚îÄ‚îÄ üìÑ metrics.py          # M√©tricas de avalia√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ helpers.py          # Fun√ß√µes auxiliares
‚îú‚îÄ‚îÄ üìÅ data/                       # Dados do projeto
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ raw/                    # Dados brutos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ twitter/            # Dados do Twitter
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ reviews/            # Reviews de produtos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ news/               # Artigos de not√≠cias
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ surveys/            # Pesquisas e question√°rios
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ processed/              # Dados processados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ cleaned/            # Dados limpos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ tokenized/          # Dados tokenizados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ features/           # Features extra√≠das
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ labeled/                # Dados rotulados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ sentiment/          # Dados de sentimento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ emotion/            # Dados de emo√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ aspects/            # Dados de aspectos
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ external/               # Dados externos
‚îÇ       ‚îú‚îÄ‚îÄ üìÅ lexicons/           # L√©xicos de sentimento
‚îÇ       ‚îú‚îÄ‚îÄ üìÅ embeddings/         # Word embeddings
‚îÇ       ‚îî‚îÄ‚îÄ üìÅ pretrained/         # Modelos pr√©-treinados
‚îú‚îÄ‚îÄ üìÅ notebooks/                  # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 01_data_exploration.ipynb # Explora√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 02_preprocessing.ipynb  # Pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 03_classical_models.ipynb # Modelos cl√°ssicos
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 04_transformer_models.ipynb # Modelos Transformer
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 05_ensemble_methods.ipynb # M√©todos ensemble
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 06_multilingual_analysis.ipynb # An√°lise multil√≠ngue
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 07_aspect_based_sentiment.ipynb # Sentimento por aspecto
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 08_emotion_analysis.ipynb # An√°lise de emo√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ 09_trend_analysis.ipynb # An√°lise de tend√™ncias
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ 10_model_deployment.ipynb # Deployment de modelos
‚îú‚îÄ‚îÄ üìÅ experiments/                # Experimentos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ hyperparameter_tuning/  # Otimiza√ß√£o de hiperpar√¢metros
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ model_comparison/       # Compara√ß√£o de modelos
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ cross_validation/       # Valida√ß√£o cruzada
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ ablation_studies/       # Estudos de abla√ß√£o
‚îú‚îÄ‚îÄ üìÅ models/                     # Modelos treinados
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ sentiment/              # Modelos de sentimento
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ emotion/                # Modelos de emo√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ aspects/                # Modelos de aspectos
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ multilingual/           # Modelos multil√≠ngues
‚îú‚îÄ‚îÄ üìÅ tests/                      # Testes automatizados
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ test_preprocessing.py   # Testes pr√©-processamento
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ test_models.py          # Testes de modelos
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ test_api.py             # Testes da API
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ test_analysis.py        # Testes de an√°lise
‚îú‚îÄ‚îÄ üìÅ docker/                     # Containers Docker
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Dockerfile.api          # Container da API
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Dockerfile.dashboard    # Container do dashboard
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ docker-compose.yml      # Orquestra√ß√£o
‚îú‚îÄ‚îÄ üìÅ configs/                    # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ model_configs.yaml      # Configura√ß√µes de modelos
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ api_config.yaml         # Configura√ß√£o da API
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ data_sources.yaml       # Configura√ß√£o de fontes
‚îú‚îÄ‚îÄ üìÑ requirements.txt            # Depend√™ncias Python
‚îú‚îÄ‚îÄ üìÑ requirements-dev.txt        # Depend√™ncias desenvolvimento
‚îú‚îÄ‚îÄ üìÑ setup.py                    # Setup do pacote
‚îú‚îÄ‚îÄ üìÑ README.md                   # Este arquivo
‚îú‚îÄ‚îÄ üìÑ LICENSE                     # Licen√ßa MIT
‚îî‚îÄ‚îÄ üìÑ .gitignore                 # Arquivos ignorados
```

### üß† Modelos Implementados

#### 1. ü§ñ Modelos Transformer

**BERT para An√°lise de Sentimentos**
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

class BERTSentimentAnalyzer:
    def __init__(self, model_name="neuralmind/bert-base-portuguese-cased"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        self.model.eval()
    
    def predict_sentiment(self, text, return_probabilities=True):
        """Predizer sentimento de um texto"""
        # Tokeniza√ß√£o
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=512
        ).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            
            if return_probabilities:
                probabilities = F.softmax(logits, dim=-1)
                return {
                    'sentiment': self._get_sentiment_label(logits),
                    'confidence': float(torch.max(probabilities)),
                    'probabilities': {
                        'negative': float(probabilities[0][0]),
                        'neutral': float(probabilities[0][1]),
                        'positive': float(probabilities[0][2])
                    }
                }
            else:
                return self._get_sentiment_label(logits)
    
    def batch_predict(self, texts, batch_size=32):
        """Predi√ß√£o em lote para m√∫ltiplos textos"""
        results = []
        
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            
            # Tokeniza√ß√£o do lote
            inputs = self.tokenizer(
                batch_texts,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probabilities = F.softmax(logits, dim=-1)
                
                for j, text in enumerate(batch_texts):
                    results.append({
                        'text': text,
                        'sentiment': self._get_sentiment_label(logits[j:j+1]),
                        'confidence': float(torch.max(probabilities[j])),
                        'probabilities': {
                            'negative': float(probabilities[j][0]),
                            'neutral': float(probabilities[j][1]),
                            'positive': float(probabilities[j][2])
                        }
                    })
        
        return results
    
    def _get_sentiment_label(self, logits):
        """Converter logits para r√≥tulo de sentimento"""
        predicted_class = torch.argmax(logits, dim=-1).item()
        labels = ['negative', 'neutral', 'positive']
        return labels[predicted_class]
    
    def fine_tune(self, train_dataset, val_dataset, epochs=3, learning_rate=2e-5):
        """Fine-tuning do modelo com dados customizados"""
        from torch.utils.data import DataLoader
        from transformers import AdamW, get_linear_schedule_with_warmup
        
        # Configurar otimizador
        optimizer = AdamW(self.model.parameters(), lr=learning_rate)
        
        # Configurar scheduler
        total_steps = len(train_dataset) * epochs
        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=0,
            num_training_steps=total_steps
        )
        
        # DataLoaders
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
        
        self.model.train()
        
        for epoch in range(epochs):
            total_loss = 0
            
            for batch in train_loader:
                optimizer.zero_grad()
                
                inputs = {
                    'input_ids': batch['input_ids'].to(self.device),
                    'attention_mask': batch['attention_mask'].to(self.device),
                    'labels': batch['labels'].to(self.device)
                }
                
                outputs = self.model(**inputs)
                loss = outputs.loss
                loss.backward()
                
                optimizer.step()
                scheduler.step()
                
                total_loss += loss.item()
            
            # Valida√ß√£o
            val_accuracy = self._evaluate(val_loader)
            print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Accuracy: {val_accuracy:.4f}")
```

**RoBERTa para An√°lise de Emo√ß√µes**
```python
class RoBERTaEmotionAnalyzer:
    def __init__(self, model_name="j-hartmann/emotion-english-distilroberta-base"):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        self.model.eval()
        
        # Mapeamento de emo√ß√µes
        self.emotion_labels = [
            'sadness', 'joy', 'love', 'anger', 'fear', 'surprise'
        ]
    
    def analyze_emotions(self, text):
        """Analisar emo√ß√µes em um texto"""
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=512
        ).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probabilities = F.softmax(logits, dim=-1)
            
            # Criar dicion√°rio de emo√ß√µes com probabilidades
            emotion_scores = {}
            for i, emotion in enumerate(self.emotion_labels):
                emotion_scores[emotion] = float(probabilities[0][i])
            
            # Emo√ß√£o dominante
            dominant_emotion = max(emotion_scores, key=emotion_scores.get)
            
            return {
                'dominant_emotion': dominant_emotion,
                'confidence': emotion_scores[dominant_emotion],
                'all_emotions': emotion_scores,
                'emotion_intensity': self._calculate_intensity(emotion_scores)
            }
    
    def _calculate_intensity(self, emotion_scores):
        """Calcular intensidade emocional geral"""
        # Excluir emo√ß√µes neutras e calcular intensidade
        intense_emotions = ['anger', 'fear', 'sadness', 'joy', 'love', 'surprise']
        total_intensity = sum(emotion_scores[emotion] for emotion in intense_emotions)
        return total_intensity
    
    def emotion_timeline(self, texts, timestamps=None):
        """Analisar evolu√ß√£o emocional ao longo do tempo"""
        results = []
        
        for i, text in enumerate(texts):
            emotion_analysis = self.analyze_emotions(text)
            
            result = {
                'index': i,
                'text': text,
                'timestamp': timestamps[i] if timestamps else i,
                **emotion_analysis
            }
            results.append(result)
        
        return results
```

#### 2. üìä An√°lise de Aspectos (ABSA)

**Aspect-Based Sentiment Analysis**
```python
import spacy
from collections import defaultdict

class AspectBasedSentimentAnalyzer:
    def __init__(self):
        self.nlp = spacy.load("pt_core_news_sm")
        self.sentiment_analyzer = BERTSentimentAnalyzer()
        
        # Aspectos pr√©-definidos para diferentes dom√≠nios
        self.aspect_keywords = {
            'restaurant': {
                'food': ['comida', 'prato', 'sabor', 'tempero', 'ingrediente'],
                'service': ['atendimento', 'gar√ßom', 'servi√ßo', 'staff'],
                'ambiance': ['ambiente', 'decora√ß√£o', 'm√∫sica', 'ilumina√ß√£o'],
                'price': ['pre√ßo', 'valor', 'custo', 'caro', 'barato']
            },
            'hotel': {
                'room': ['quarto', 'cama', 'banheiro', 'limpeza'],
                'service': ['atendimento', 'recep√ß√£o', 'staff'],
                'location': ['localiza√ß√£o', 'local', 'acesso', 'transporte'],
                'amenities': ['wifi', 'piscina', 'academia', 'caf√©']
            },
            'product': {
                'quality': ['qualidade', 'material', 'durabilidade'],
                'design': ['design', 'apar√™ncia', 'cor', 'estilo'],
                'functionality': ['funcionalidade', 'performance', 'uso'],
                'price': ['pre√ßo', 'valor', 'custo-benef√≠cio']
            }
        }
    
    def extract_aspects_and_sentiments(self, text, domain='general'):
        """Extrair aspectos e seus sentimentos"""
        doc = self.nlp(text)
        
        # Extrair aspectos mencionados
        aspects_found = self._extract_aspects(text, domain)
        
        # Analisar sentimento para cada aspecto
        aspect_sentiments = {}
        
        for aspect, mentions in aspects_found.items():
            if mentions:
                # Extrair senten√ßas que mencionam o aspecto
                aspect_sentences = self._extract_aspect_sentences(text, mentions)
                
                # Analisar sentimento das senten√ßas
                sentiments = []
                for sentence in aspect_sentences:
                    sentiment = self.sentiment_analyzer.predict_sentiment(sentence)
                    sentiments.append(sentiment)
                
                # Agregar sentimentos
                aspect_sentiments[aspect] = self._aggregate_sentiments(sentiments)
        
        return {
            'aspects_found': aspects_found,
            'aspect_sentiments': aspect_sentiments,
            'overall_sentiment': self.sentiment_analyzer.predict_sentiment(text)
        }
    
    def _extract_aspects(self, text, domain):
        """Extrair aspectos mencionados no texto"""
        text_lower = text.lower()
        aspects_found = defaultdict(list)
        
        if domain in self.aspect_keywords:
            for aspect, keywords in self.aspect_keywords[domain].items():
                for keyword in keywords:
                    if keyword in text_lower:
                        aspects_found[aspect].append(keyword)
        
        return dict(aspects_found)
    
    def _extract_aspect_sentences(self, text, aspect_mentions):
        """Extrair senten√ßas que mencionam aspectos espec√≠ficos"""
        doc = self.nlp(text)
        aspect_sentences = []
        
        for sent in doc.sents:
            sent_text = sent.text.lower()
            for mention in aspect_mentions:
                if mention in sent_text:
                    aspect_sentences.append(sent.text)
                    break
        
        return aspect_sentences
    
    def _aggregate_sentiments(self, sentiments):
        """Agregar m√∫ltiplos sentimentos para um aspecto"""
        if not sentiments:
            return None
        
        # Calcular m√©dias das probabilidades
        avg_probs = {
            'negative': sum(s['probabilities']['negative'] for s in sentiments) / len(sentiments),
            'neutral': sum(s['probabilities']['neutral'] for s in sentiments) / len(sentiments),
            'positive': sum(s['probabilities']['positive'] for s in sentiments) / len(sentiments)
        }
        
        # Determinar sentimento dominante
        dominant_sentiment = max(avg_probs, key=avg_probs.get)
        
        return {
            'sentiment': dominant_sentiment,
            'confidence': avg_probs[dominant_sentiment],
            'probabilities': avg_probs,
            'num_mentions': len(sentiments)
        }
```

#### 3. üåç An√°lise Multil√≠ngue

**Detector de Idioma e An√°lise Multil√≠ngue**
```python
from langdetect import detect, detect_langs
import polyglot
from polyglot.text import Text

class MultilingualSentimentAnalyzer:
    def __init__(self):
        # Modelos espec√≠ficos por idioma
        self.models = {
            'pt': BERTSentimentAnalyzer("neuralmind/bert-base-portuguese-cased"),
            'en': BERTSentimentAnalyzer("cardiffnlp/twitter-roberta-base-sentiment-latest"),
            'es': BERTSentimentAnalyzer("pysentimiento/robertuito-sentiment-analysis"),
            'fr': BERTSentimentAnalyzer("tblard/tf-allocine"),
        }
        
        # Modelo multil√≠ngue como fallback
        self.multilingual_model = BERTSentimentAnalyzer("cardiffnlp/twitter-xlm-roberta-base-sentiment")
    
    def detect_language(self, text):
        """Detectar idioma do texto"""
        try:
            # Detec√ß√£o principal
            language = detect(text)
            
            # Detec√ß√£o com probabilidades
            lang_probs = detect_langs(text)
            
            return {
                'language': language,
                'confidence': lang_probs[0].prob,
                'all_languages': [(lang.lang, lang.prob) for lang in lang_probs]
            }
        except:
            return {
                'language': 'unknown',
                'confidence': 0.0,
                'all_languages': []
            }
    
    def analyze_multilingual_sentiment(self, text):
        """Analisar sentimento considerando o idioma"""
        # Detectar idioma
        lang_info = self.detect_language(text)
        detected_lang = lang_info['language']
        
        # Escolher modelo apropriado
        if detected_lang in self.models and lang_info['confidence'] > 0.8:
            model = self.models[detected_lang]
            model_used = f"language_specific_{detected_lang}"
        else:
            model = self.multilingual_model
            model_used = "multilingual_fallback"
        
        # Analisar sentimento
        sentiment_result = model.predict_sentiment(text)
        
        # Adicionar informa√ß√µes de idioma
        sentiment_result.update({
            'detected_language': detected_lang,
            'language_confidence': lang_info['confidence'],
            'model_used': model_used
        })
        
        return sentiment_result
    
    def cross_lingual_analysis(self, texts_dict):
        """An√°lise comparativa entre idiomas"""
        results = {}
        
        for lang, texts in texts_dict.items():
            lang_results = []
            
            for text in texts:
                result = self.analyze_multilingual_sentiment(text)
                lang_results.append(result)
            
            # Agregar resultados por idioma
            results[lang] = {
                'individual_results': lang_results,
                'aggregated': self._aggregate_language_results(lang_results)
            }
        
        return results
    
    def _aggregate_language_results(self, results):
        """Agregar resultados de um idioma"""
        if not results:
            return None
        
        # Calcular distribui√ß√£o de sentimentos
        sentiment_counts = {'positive': 0, 'neutral': 0, 'negative': 0}
        total_confidence = 0
        
        for result in results:
            sentiment_counts[result['sentiment']] += 1
            total_confidence += result['confidence']
        
        total_texts = len(results)
        
        return {
            'total_texts': total_texts,
            'sentiment_distribution': {
                k: v/total_texts for k, v in sentiment_counts.items()
            },
            'average_confidence': total_confidence / total_texts,
            'dominant_sentiment': max(sentiment_counts, key=sentiment_counts.get)
        }
```

### üåê API REST

**FastAPI para An√°lise em Tempo Real**
```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import List, Optional
import asyncio

app = FastAPI(
    title="NLP Sentiment Analysis API",
    description="API completa para an√°lise de sentimentos e processamento de linguagem natural",
    version="1.0.0"
)

# Modelos Pydantic
class TextInput(BaseModel):
    text: str
    language: Optional[str] = None
    domain: Optional[str] = "general"

class BatchTextInput(BaseModel):
    texts: List[str]
    language: Optional[str] = None
    domain: Optional[str] = "general"

class SentimentResponse(BaseModel):
    sentiment: str
    confidence: float
    probabilities: dict
    processing_time: float

# Inicializar analisadores
sentiment_analyzer = BERTSentimentAnalyzer()
emotion_analyzer = RoBERTaEmotionAnalyzer()
aspect_analyzer = AspectBasedSentimentAnalyzer()
multilingual_analyzer = MultilingualSentimentAnalyzer()

@app.post("/analyze/sentiment", response_model=SentimentResponse)
async def analyze_sentiment(input_data: TextInput):
    """Analisar sentimento de um texto"""
    import time
    start_time = time.time()
    
    try:
        if input_data.language:
            # Usar modelo espec√≠fico do idioma se especificado
            result = multilingual_analyzer.analyze_multilingual_sentiment(input_data.text)
        else:
            # Usar modelo padr√£o
            result = sentiment_analyzer.predict_sentiment(input_data.text)
        
        processing_time = time.time() - start_time
        
        return SentimentResponse(
            sentiment=result['sentiment'],
            confidence=result['confidence'],
            probabilities=result['probabilities'],
            processing_time=processing_time
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/emotions")
async def analyze_emotions(input_data: TextInput):
    """Analisar emo√ß√µes de um texto"""
    try:
        result = emotion_analyzer.analyze_emotions(input_data.text)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/aspects")
async def analyze_aspects(input_data: TextInput):
    """An√°lise de sentimentos baseada em aspectos"""
    try:
        result = aspect_analyzer.extract_aspects_and_sentiments(
            input_data.text, 
            input_data.domain
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/batch")
async def batch_analyze(input_data: BatchTextInput):
    """An√°lise em lote de m√∫ltiplos textos"""
    try:
        results = sentiment_analyzer.batch_predict(input_data.texts)
        return {"results": results, "total_processed": len(results)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/comprehensive")
async def comprehensive_analysis(input_data: TextInput):
    """An√°lise completa: sentimento, emo√ß√µes e aspectos"""
    try:
        # Executar an√°lises em paralelo
        sentiment_task = asyncio.create_task(
            asyncio.to_thread(sentiment_analyzer.predict_sentiment, input_data.text)
        )
        emotion_task = asyncio.create_task(
            asyncio.to_thread(emotion_analyzer.analyze_emotions, input_data.text)
        )
        aspect_task = asyncio.create_task(
            asyncio.to_thread(
                aspect_analyzer.extract_aspects_and_sentiments, 
                input_data.text, 
                input_data.domain
            )
        )
        
        # Aguardar resultados
        sentiment_result = await sentiment_task
        emotion_result = await emotion_task
        aspect_result = await aspect_task
        
        return {
            "sentiment_analysis": sentiment_result,
            "emotion_analysis": emotion_result,
            "aspect_analysis": aspect_result,
            "text": input_data.text
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Verifica√ß√£o de sa√∫de da API"""
    return {"status": "healthy", "models_loaded": True}

# Middleware para logging
@app.middleware("http")
async def log_requests(request, call_next):
    import time
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    print(f"Path: {request.url.path}, Method: {request.method}, Time: {process_time:.4f}s")
    return response
```

### üìä Dashboard Streamlit

**Interface Interativa**
```python
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import pandas as pd

st.set_page_config(
    page_title="NLP Sentiment Analysis Dashboard",
    page_icon="üß†",
    layout="wide"
)

class SentimentDashboard:
    def __init__(self):
        self.sentiment_analyzer = BERTSentimentAnalyzer()
        self.emotion_analyzer = RoBERTaEmotionAnalyzer()
        self.aspect_analyzer = AspectBasedSentimentAnalyzer()
    
    def main(self):
        st.title("üß† NLP Sentiment Analysis Dashboard")
        st.sidebar.title("Navega√ß√£o")
        
        page = st.sidebar.selectbox(
            "Escolha uma an√°lise",
            ["An√°lise Individual", "An√°lise em Lote", "An√°lise de Aspectos", 
             "An√°lise de Emo√ß√µes", "Compara√ß√£o de Modelos", "An√°lise Temporal"]
        )
        
        if page == "An√°lise Individual":
            self.individual_analysis()
        elif page == "An√°lise em Lote":
            self.batch_analysis()
        elif page == "An√°lise de Aspectos":
            self.aspect_analysis()
        elif page == "An√°lise de Emo√ß√µes":
            self.emotion_analysis()
        elif page == "Compara√ß√£o de Modelos":
            self.model_comparison()
        elif page == "An√°lise Temporal":
            self.temporal_analysis()
    
    def individual_analysis(self):
        st.header("üìù An√°lise Individual de Texto")
        
        # Input de texto
        text_input = st.text_area(
            "Digite o texto para an√°lise:",
            height=150,
            placeholder="Ex: Adorei o produto! A qualidade √© excelente e o atendimento foi perfeito."
        )
        
        if st.button("Analisar Sentimento") and text_input:
            with st.spinner("Analisando..."):
                # An√°lise de sentimento
                sentiment_result = self.sentiment_analyzer.predict_sentiment(text_input)
                
                # Exibir resultados
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        "Sentimento",
                        sentiment_result['sentiment'].title(),
                        f"{sentiment_result['confidence']:.2%}"
                    )
                
                with col2:
                    # Gr√°fico de barras das probabilidades
                    probs_df = pd.DataFrame([sentiment_result['probabilities']]).T
                    probs_df.columns = ['Probabilidade']
                    fig = px.bar(probs_df, y=probs_df.index, x='Probabilidade', 
                               orientation='h', title="Distribui√ß√£o de Probabilidades")
                    st.plotly_chart(fig, use_container_width=True)
                
                with col3:
                    # Medidor de sentimento
                    self.sentiment_gauge(sentiment_result['probabilities'])
    
    def sentiment_gauge(self, probabilities):
        """Criar medidor de sentimento"""
        # Calcular score (-1 a 1)
        score = probabilities['positive'] - probabilities['negative']
        
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "Score de Sentimento"},
            delta = {'reference': 0},
            gauge = {
                'axis': {'range': [-1, 1]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [-1, -0.3], 'color': "lightcoral"},
                    {'range': [-0.3, 0.3], 'color': "lightyellow"},
                    {'range': [0.3, 1], 'color': "lightgreen"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 0.9
                }
            }
        ))
        
        st.plotly_chart(fig, use_container_width=True)
    
    def batch_analysis(self):
        st.header("üìä An√°lise em Lote")
        
        # Upload de arquivo
        uploaded_file = st.file_uploader(
            "Fa√ßa upload de um arquivo CSV com textos",
            type=['csv']
        )
        
        if uploaded_file:
            df = pd.read_csv(uploaded_file)
            st.write("Preview dos dados:")
            st.dataframe(df.head())
            
            text_column = st.selectbox(
                "Selecione a coluna com os textos:",
                df.columns
            )
            
            if st.button("Analisar Todos os Textos"):
                with st.spinner("Processando..."):
                    # An√°lise em lote
                    texts = df[text_column].tolist()
                    results = self.sentiment_analyzer.batch_predict(texts)
                    
                    # Criar DataFrame com resultados
                    results_df = pd.DataFrame(results)
                    
                    # Estat√≠sticas gerais
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("Total de Textos", len(results))
                    
                    with col2:
                        positive_pct = len([r for r in results if r['sentiment'] == 'positive']) / len(results)
                        st.metric("% Positivos", f"{positive_pct:.1%}")
                    
                    with col3:
                        avg_confidence = sum(r['confidence'] for r in results) / len(results)
                        st.metric("Confian√ßa M√©dia", f"{avg_confidence:.2%}")
                    
                    # Gr√°ficos
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Distribui√ß√£o de sentimentos
                        sentiment_counts = results_df['sentiment'].value_counts()
                        fig = px.pie(values=sentiment_counts.values, names=sentiment_counts.index,
                                   title="Distribui√ß√£o de Sentimentos")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # Histograma de confian√ßa
                        fig = px.histogram(results_df, x='confidence', nbins=20,
                                         title="Distribui√ß√£o de Confian√ßa")
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # Tabela de resultados
                    st.subheader("Resultados Detalhados")
                    st.dataframe(results_df)
                    
                    # Download dos resultados
                    csv = results_df.to_csv(index=False)
                    st.download_button(
                        "Download dos Resultados",
                        csv,
                        "sentiment_analysis_results.csv",
                        "text/csv"
                    )

# Executar dashboard
if __name__ == "__main__":
    dashboard = SentimentDashboard()
    dashboard.main()
```

### üéØ Aplica√ß√µes Pr√°ticas

#### 1. üì± Monitoramento de Redes Sociais

**An√°lise de Sentimento no Twitter**
```python
class SocialMediaMonitor:
    def __init__(self):
        self.sentiment_analyzer = MultilingualSentimentAnalyzer()
        self.emotion_analyzer = RoBERTaEmotionAnalyzer()
    
    def monitor_brand_sentiment(self, brand_name, num_tweets=1000):
        """Monitorar sentimento sobre uma marca"""
        # Coletar tweets (simulado)
        tweets = self._collect_tweets(brand_name, num_tweets)
        
        # Analisar sentimentos
        results = []
        for tweet in tweets:
            sentiment = self.sentiment_analyzer.analyze_multilingual_sentiment(tweet['text'])
            emotion = self.emotion_analyzer.analyze_emotions(tweet['text'])
            
            results.append({
                'tweet_id': tweet['id'],
                'text': tweet['text'],
                'timestamp': tweet['timestamp'],
                'user': tweet['user'],
                'sentiment': sentiment['sentiment'],
                'sentiment_confidence': sentiment['confidence'],
                'dominant_emotion': emotion['dominant_emotion'],
                'emotion_intensity': emotion['emotion_intensity']
            })
        
        # An√°lise agregada
        analysis = self._aggregate_social_analysis(results)
        
        return {
            'brand': brand_name,
            'total_mentions': len(results),
            'individual_results': results,
            'aggregated_analysis': analysis,
            'recommendations': self._generate_recommendations(analysis)
        }
    
    def _aggregate_social_analysis(self, results):
        """Agregar an√°lise de redes sociais"""
        if not results:
            return None
        
        # Distribui√ß√£o de sentimentos
        sentiment_dist = {}
        emotion_dist = {}
        
        for result in results:
            sentiment = result['sentiment']
            emotion = result['dominant_emotion']
            
            sentiment_dist[sentiment] = sentiment_dist.get(sentiment, 0) + 1
            emotion_dist[emotion] = emotion_dist.get(emotion, 0) + 1
        
        # Calcular m√©tricas
        total = len(results)
        positive_ratio = sentiment_dist.get('positive', 0) / total
        negative_ratio = sentiment_dist.get('negative', 0) / total
        
        # Score de sentimento da marca
        brand_sentiment_score = positive_ratio - negative_ratio
        
        return {
            'sentiment_distribution': sentiment_dist,
            'emotion_distribution': emotion_dist,
            'positive_ratio': positive_ratio,
            'negative_ratio': negative_ratio,
            'brand_sentiment_score': brand_sentiment_score,
            'avg_sentiment_confidence': sum(r['sentiment_confidence'] for r in results) / total,
            'avg_emotion_intensity': sum(r['emotion_intensity'] for r in results) / total
        }
```

#### 2. üõçÔ∏è An√°lise de Reviews de Produtos

**Sistema de An√°lise de Reviews**
```python
class ProductReviewAnalyzer:
    def __init__(self):
        self.aspect_analyzer = AspectBasedSentimentAnalyzer()
        self.sentiment_analyzer = BERTSentimentAnalyzer()
    
    def analyze_product_reviews(self, product_id, reviews):
        """Analisar reviews de um produto"""
        analysis_results = []
        
        for review in reviews:
            # An√°lise completa do review
            result = {
                'review_id': review['id'],
                'rating': review['rating'],
                'text': review['text'],
                'date': review['date'],
                'overall_sentiment': self.sentiment_analyzer.predict_sentiment(review['text']),
                'aspect_analysis': self.aspect_analyzer.extract_aspects_and_sentiments(
                    review['text'], 'product'
                )
            }
            analysis_results.append(result)
        
        # An√°lise agregada
        product_insights = self._generate_product_insights(analysis_results)
        
        return {
            'product_id': product_id,
            'total_reviews': len(reviews),
            'individual_analyses': analysis_results,
            'product_insights': product_insights,
            'improvement_suggestions': self._suggest_improvements(product_insights)
        }
    
    def _generate_product_insights(self, analyses):
        """Gerar insights do produto"""
        if not analyses:
            return None
        
        # An√°lise por aspecto
        aspect_insights = {}
        overall_sentiments = []
        
        for analysis in analyses:
            overall_sentiments.append(analysis['overall_sentiment']['sentiment'])
            
            for aspect, sentiment_data in analysis['aspect_analysis']['aspect_sentiments'].items():
                if aspect not in aspect_insights:
                    aspect_insights[aspect] = []
                aspect_insights[aspect].append(sentiment_data['sentiment'])
        
        # Calcular scores por aspecto
        aspect_scores = {}
        for aspect, sentiments in aspect_insights.items():
            positive_count = sentiments.count('positive')
            negative_count = sentiments.count('negative')
            total_count = len(sentiments)
            
            aspect_scores[aspect] = {
                'positive_ratio': positive_count / total_count,
                'negative_ratio': negative_count / total_count,
                'total_mentions': total_count,
                'score': (positive_count - negative_count) / total_count
            }
        
        # Score geral do produto
        positive_overall = overall_sentiments.count('positive')
        negative_overall = overall_sentiments.count('negative')
        total_overall = len(overall_sentiments)
        
        overall_score = (positive_overall - negative_overall) / total_overall
        
        return {
            'overall_score': overall_score,
            'overall_sentiment_distribution': {
                'positive': positive_overall / total_overall,
                'negative': negative_overall / total_overall,
                'neutral': overall_sentiments.count('neutral') / total_overall
            },
            'aspect_scores': aspect_scores,
            'strongest_aspects': self._get_top_aspects(aspect_scores, 'positive'),
            'weakest_aspects': self._get_top_aspects(aspect_scores, 'negative')
        }
    
    def _suggest_improvements(self, insights):
        """Sugerir melhorias baseadas na an√°lise"""
        suggestions = []
        
        # Identificar aspectos problem√°ticos
        for aspect, scores in insights['aspect_scores'].items():
            if scores['score'] < -0.3 and scores['total_mentions'] >= 5:
                suggestions.append({
                    'priority': 'high',
                    'aspect': aspect,
                    'issue': f"Aspecto {aspect} tem sentimento predominantemente negativo",
                    'recommendation': f"Focar em melhorias no aspecto {aspect}"
                })
        
        # Sugest√µes baseadas no score geral
        if insights['overall_score'] < 0:
            suggestions.append({
                'priority': 'critical',
                'aspect': 'overall',
                'issue': "Sentimento geral do produto √© negativo",
                'recommendation': "Revisar estrat√©gia geral do produto"
            })
        
        return suggestions
```

### üéØ Compet√™ncias Demonstradas

#### NLP e Deep Learning
- ‚úÖ **Modelos Transformer**: BERT, RoBERTa, DistilBERT, XLNet
- ‚úÖ **Transfer Learning**: Fine-tuning para dom√≠nios espec√≠ficos
- ‚úÖ **Multilingual NLP**: Processamento em m√∫ltiplos idiomas
- ‚úÖ **Aspect-Based Sentiment**: An√°lise granular por aspectos

#### An√°lise de Texto
- ‚úÖ **Sentiment Analysis**: Classifica√ß√£o de polaridade
- ‚úÖ **Emotion Analysis**: Detec√ß√£o de emo√ß√µes espec√≠ficas
- ‚úÖ **Topic Modeling**: Extra√ß√£o de t√≥picos
- ‚úÖ **Text Classification**: Classifica√ß√£o autom√°tica

#### Engenharia de Software
- ‚úÖ **API Development**: FastAPI para produ√ß√£o
- ‚úÖ **Dashboard Development**: Streamlit para visualiza√ß√£o
- ‚úÖ **Batch Processing**: Processamento em lote eficiente
- ‚úÖ **Model Deployment**: Deploy de modelos em produ√ß√£o

---

## üá∫üá∏ English

### üß† Overview

Comprehensive **sentiment analysis and natural language processing** platform developed in Python:

- ü§ñ **Transformer Models**: BERT, RoBERTa, DistilBERT, XLNet
- üìä **Multidimensional Analysis**: Sentiment, emotion, aspects, polarity
- üåç **Multilingual**: Support for Portuguese, English, Spanish
- üîÑ **Complete Pipeline**: Preprocessing, analysis, visualization
- üåê **REST API**: Endpoints for real-time integration
- üìà **Dashboard**: Interactive interface with Streamlit

### üéØ Platform Objectives

- **Analyze sentiments** in texts from multiple sources
- **Extract insights** from unstructured textual data
- **Monitor public opinion** on social media and reviews
- **Automate classification** of customer feedback
- **Facilitate decision-making** based on textual analysis

### üß† Implemented Models

#### 1. ü§ñ Transformer Models
- BERT for sentiment analysis
- RoBERTa for emotion analysis
- DistilBERT for aspect analysis
- Multilingual BERT for cross-language analysis

#### 2. üìä Aspect Analysis (ABSA)
- Aspect extraction from text
- Sentiment analysis per aspect
- Domain-specific aspect detection
- Aggregated aspect insights

#### 3. üåç Multilingual Analysis
- Language detection
- Language-specific models
- Cross-lingual comparison
- Multilingual fallback models

### üéØ Skills Demonstrated

#### NLP and Deep Learning
- ‚úÖ **Transformer Models**: BERT, RoBERTa, DistilBERT, XLNet
- ‚úÖ **Transfer Learning**: Fine-tuning for specific domains
- ‚úÖ **Multilingual NLP**: Multi-language processing
- ‚úÖ **Aspect-Based Sentiment**: Granular aspect analysis

#### Text Analysis
- ‚úÖ **Sentiment Analysis**: Polarity classification
- ‚úÖ **Emotion Analysis**: Specific emotion detection
- ‚úÖ **Topic Modeling**: Topic extraction
- ‚úÖ **Text Classification**: Automatic classification

#### Software Engineering
- ‚úÖ **API Development**: FastAPI for production
- ‚úÖ **Dashboard Development**: Streamlit for visualization
- ‚úÖ **Batch Processing**: Efficient batch processing
- ‚úÖ **Model Deployment**: Production model deployment

---

## üìÑ Licen√ßa | License

MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes | see [LICENSE](LICENSE) file for details

## üìû Contato | Contact

**GitHub**: [@galafis](https://github.com/galafis)  
**LinkedIn**: [Gabriel Demetrios Lafis](https://linkedin.com/in/galafis)  
**Email**: gabriel.lafis@example.com

---

<div align="center">

**Desenvolvido com ‚ù§Ô∏è para Processamento de Linguagem Natural | Developed with ‚ù§Ô∏è for Natural Language Processing**

[![GitHub](https://img.shields.io/badge/GitHub-galafis-blue?style=flat-square&logo=github)](https://github.com/galafis)
[![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)

</div>

